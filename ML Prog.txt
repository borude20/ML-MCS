1#Write a Python program to prepare Scatter Plot for Iris Dataset (Slip 1,10,13,22)

#Importing Liabraries
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
#Importing DataSet
iris=pd.read_csv("iris.csv")
iris.plot(kind='scatter',x='sepal_length',y='sepal_width')
iris.plot(kind='scatter',x='petal_length',y='petal_width')
sns.set_style("whitegrid");
sns.FacetGrid(iris,hue="species",height=4).map(plt.scatter,"sepal_length","sepal_width").add_legend()
sns.FacetGrid(iris,hue="species",height=4).map(plt.scatter,"petal_length","petal_width").add_legend()

----------------------------------------------------------------------------------------------------

2#Write a python program to find all null values in a given dataset and remove them. (Slip 2,11,14,23)
import pandas as pd  
dataset = pd.read_csv('AirQuality.csv')
a=dataset.isnull()
print (a)

b=dataset.isnull().sum()
print(b)

modifieddataset=dataset.fillna(" ")
c=modifieddataset.isnull().sum()
print(c)
print(modifieddataset)

#To remove rows with null values 
dataset=dataset.dropna()
print(dataset)
d=dataset.isnull().sum()
print(d)

--------------------------------------------------------------------------------------------

3#Write a python program to make Categorical values in numeric format for a given dataset (Slip 3,12,15,24)

#Data Preprocessing Steps Using Python

#Step 1 #Importing Libraries
import numpy as np
import pandas as pd
#-----------------------------------------------------------------------

#Step 2 # Importing Dataset

data=pd.read_csv("E:\ML_Program\Dataset\Data.csv")
print("Complete Dataset")
print(data)

#Step 5 #Encoding Categorial Data
#Encoding Independent Variable
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder

ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])], remainder="passthrough")
X = np.array(ct.fit_transform(X))
print(" Output of Independent Variable After Encoding: ")
print(X)
print("----------------------------------------------------------------------------------------------------------")
#Encoding Dependent Variable
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)
print(" Output of Dependent Variable After Encoding: ")
print(y)

-------------------------------------------------------------------------------------------------------

4#Write a python program to Implement Simple Linear Regression for predicting house price. (Download kc_house_data  dataset). (Slip 4,16,25)

#Importing libraries
import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt 

#Importing DataSet 
dataset=pd.read_csv("kc_house_data.csv")
#print(dataset)
X=np.array(dataset['sqft_living']).reshape(-1,1)
#print(X)

y=np.array(dataset['price']).reshape(-1,1)

#Splitting the data into Train and Test
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=0)

#Fitting simple linear regression to the Training Set
from sklearn.linear_model import LinearRegression 
regressor = LinearRegression()
regressor.fit(X_train, y_train)

#Predicting the prices
pred = regressor.predict(X_test)

#Visualizing the training Test Results 
plt.scatter(X_train, y_train, color= 'red')
plt.plot(X_train, regressor.predict(X_train), color = 'blue')
plt.title ("Visuals for Training Dataset")
plt.xlabel("Space")
plt.ylabel("Price")
plt.show()

#Visualizing the Test Results 
plt.scatter(X_test, y_test, color= 'red')
plt.plot(X_train, regressor.predict(X_train), color = 'blue')
plt.title("Visuals for Test DataSet")
plt.xlabel("Space")
plt.ylabel("Price")
plt.show()

#Predicting Price 
sq=float(input("Enter sqft_living:="))
y_pred=regressor.predict([[sq]])

print("Predicted Price:=",  y_pred)


--------------------------------------------------------------------------------------------------------------------------

5#Write a python program to implement Multiple Linear Regression for given dataset. (Slip 5,17,26)	     

#Importing libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd# Importing the libraries


# Importing the dataset
dataset = pd.read_csv('Sal_Mul.csv')
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values
print(X)

# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

# Training the Multiple Linear Regression model on the Training set
from sklearn.linear_model import LinearRegression
regressor = LinearRegression ()
regressor.fit(X_train, y_train)
print(regressor.predict(X_test))

#Predicting the result of salary of new employee with 5 Years of total Experience, #2 years as team lead Experience, 1 year as project manager and has 2 certifications 

y_pred = regressor.predict([[5,2,1,2]])

print("Predicted Salary is for x_new is:", y_pred)

# Accuracy of Model
accuracy = (regressor.score (X_test, y_test) )
print("Accuracy of Model ",accuracy)

--------------------------------------------------------------------------------------------------------------------------------

6#Write a python program to implement Polynomial Linear Regression for given dataset (Download Position_Salaries.csv) (Slip 6,18,27)
                                                                                           
# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# Importing the dataset
dataset = pd.read_csv('pos_salaries.csv')
X = dataset.iloc[   : , 1:-1].values
y = dataset.iloc[  :  , -1].values

# Training the Linear Regression model on the whole dataset
from sklearn.linear_model import LinearRegression
lin_reg_1 = LinearRegression()
lin_reg_1.fit(X, y)

# Training the Polynomial Regression model on the whole dataset

from sklearn.preprocessing import PolynomialFeatures

poly_reg = PolynomialFeatures(degree = 4)
X_poly = poly_reg.fit_transform(X)
lin_reg_2 = LinearRegression()
lin_reg_2.fit(X_poly, y)


# Visualising the Linear Regression results
plt.scatter(X, y, color = 'red')
plt.plot(X, lin_reg_1.predict(X), color = 'blue')

plt.title('Truth or Bluff (Linear Regression)')
plt.xlabel('Position Level')
plt.ylabel('Salary')
plt.show()

# Visualising the Polynomial Regression results
plt.scatter(X, y, color = 'red')
#plt.plot(X, lin_reg_2.predict(poly_reg.fit_transform(X)), color = 'blue')
plt.plot(X, lin_reg_2.predict(X_poly), color = 'blue')
plt.title('Truth or Bluff (Polynomial Regression)')
plt.xlabel('Position level')
plt.ylabel('Salary')
plt.show()


# Predicting a new result with Linear Regression
print("Salary predicted by Linear Model:")
print(lin_reg_1.predict([[6.5]]))

# Predicting a new result with Polynomial Regression

Pred_sal=lin_reg_2.predict(poly_reg.fit_transform([[6.5]]))
print("Salary predicted by Non Linear Model:",Pred_sal)

----------------------------------------------------------------------------------------------------------------------------

7#Write a python program to implement Naive Bayes. (Slip 7,19,28)

# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# Importing the dataset
dataset = pd.read_csv('Social_Network_Ads.csv')
X=dataset.iloc[:,:-1].values
y = dataset.iloc[:, -1].values

# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)

# Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

# Training the Naive Bayes model on the Training set
from sklearn.naive_bayes import GaussianNB #based on the probabilistic approach
classifier = GaussianNB()
classifier.fit(X_train, y_train)

# Predicting the Test set results
y_pred = classifier.predict(X_test)
print(y_pred)
# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix, accuracy_score
ac = accuracy_score(y_test,y_pred)
print("Accuracy is:=",ac)
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix Is:", cm)

-------------------------------------------------------------------------------------------------------------------------

8#Write a python program to implement Decision Tree whether or not to play Tennis (Slip 8,20,29)

#Importing Libraries
import numpy as np
import pandas as pd

#Importing the Dataset
dataset = pd.read_csv("play_tennis.csv")

#Encode Categorial Data
from sklearn.preprocessing import LabelEncoder
Le = LabelEncoder()

dataset['outlook'] = Le.fit_transform(dataset['outlook'])
dataset['temp'] = Le.fit_transform(dataset['temp'])
dataset['humidity'] = Le.fit_transform(dataset['humidity'])
dataset['wind'] = Le.fit_transform(dataset['wind'])
dataset['play'] = Le.fit_transform(dataset['play'])

X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, 4].values

#print(X)
#print(y)
#Fitting Decision Tree Model
from sklearn import tree
clf = tree.DecisionTreeClassifier(criterion = 'entropy')
clf = clf.fit(X, y)

# We can visualize the tree using tree.plot_tree
tree.plot_tree(clf)

# The predictions are stored in X_pred
print(X)
X_pred = clf.predict(X)

# verifying if the model has predicted it all right.
print(X_pred)
print(X_pred == y)


----------------------------------------------------------------------------------------------------------------

9#Write a python program to implement Linear SVM. (Slip 9,21,30)

# Import the Libraries
import numpy as np
import matplotlib.pyplot as plt
from sklearn import svm, datasets

#Import some Data from the iris Data Set
iris = datasets.load_iris()

#Take only the first two features of Data.
#To avoid the slicing, Two-Dim Dataset can be used

X = iris.data[ : , :2]

y = iris.target

# C is the SVM regularization parameter
C=1.0

# Create an Instance of SVM and Fit out the data.
# Data is not scaled so as to be able to plot the support vectors
svc = svm.SVC(kernel ='linear', C = 1).fit(X, y)


# create a mesh to plot
x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1


y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1

h = (x_max / x_min)/100

print("value of h is",h)
xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
         np.arange(y_min, y_max, h))
  
# Plot the data for Proper Visual Representation
plt.subplot(1, 1, 1)

# Predict the result by giving Data to the model
Z = svc.predict(np.c_ [xx.ravel(), yy.ravel()])


print(xx.shape)
Z = Z.reshape(xx.shape)

plt.contourf(xx, yy, Z,alpha=0.8)
plt.scatter(X[:, 0], X[:, 1], c = y)
plt.xlabel('Sepal length')
plt.ylabel('Sepal width')
plt.title('SVC with linear kernel')

# Output the Plot
plt.show()

------------------------------------------------------------------------------------------------------------------

10#Write a Python program to prepare Scatter Plot for Iris Dataset. (Slip 10)

#Importing Liabraries
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
#Importing DataSet
iris=pd.read_csv("iris.csv")
iris.plot(kind='scatter',x='sepal_length',y='sepal_width')
iris.plot(kind='scatter',x='petal_length',y='petal_width')
sns.set_style("whitegrid");
sns.FacetGrid(iris,hue="species",height=4).map(plt.scatter,"sepal_length","sepal_width").add_legend()
sns.FacetGrid(iris,hue="species",height=4).map(plt.scatter,"petal_length","petal_width").add_legend()

--------------------------------------------------------------------------------------------------------------------





















